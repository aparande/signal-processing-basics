{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ranking-castle",
   "metadata": {},
   "source": [
    "# Basics of Signal Processing\n",
    "**Authors**: Anmol Parande, Hoang Nguyen, Jordan Grelling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "mobile-literature",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import scipy\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.io import wavfile\n",
    "import IPython.display as ipd"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aerial-brass",
   "metadata": {},
   "source": [
    "Throughout this notebook, we will be working with a clip from [Suzanne Vega's song, \"Tom's Diner\"](https://www.youtube.com/watch?v=FLP6QluMlrg). We will use `scipy` to read the audio data from the `.wav` file. It will return the sampling frequency `fs` as well as the audio samples."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "white-chocolate",
   "metadata": {},
   "outputs": [],
   "source": [
    "fs, audio = wavfile.read(\"toms-diner.wav\")\n",
    "print(f\"Loaded {audio.size} samples at a sampling rate of {fs}Hz\")\n",
    "ipd.Audio(audio, rate=fs)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "corrected-lease",
   "metadata": {},
   "source": [
    "# I. Time Domain Filtering - Jordan"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "instant-professional",
   "metadata": {},
   "source": [
    "## I.a Linear Filtering"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "maritime-tactics",
   "metadata": {},
   "source": [
    "## I.b Autocorrelation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "third-flesh",
   "metadata": {},
   "source": [
    "## I.c Nonlinear Filtering"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "demonstrated-rental",
   "metadata": {},
   "source": [
    "# II. DFT - Anmol\n",
    "\n",
    "Typically, when we look at signals, we look at them in the so-called time-domain. Each sample $x[k]$ represents the amplitude of the signal at time-step $k$. This tells us what the signal looks like. One question we might want to ask ourselves is _\"How fast is the signal changing?\"_\n",
    "\n",
    "For sinusoidal signals like $x[n] = \\cos(\\omega n)$ and $x[n] = \\sin(\\omega n)$, answering this question is easy because a larger $\\omega$ means the signal is changing faster ($\\omega$ is known as the angular frequency). For example, consider the plots below which each consist of 100 samples."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "painted-powder",
   "metadata": {},
   "outputs": [],
   "source": [
    "n = np.linspace(0, 100, 100)\n",
    "slow_cos = np.cos(2 * np.pi * n / 100)\n",
    "fast_cos = np.cos(2 * np.pi * 5 * n / 100)\n",
    "\n",
    "plt.figure(figsize=(15, 7))\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.stem(n, slow_cos, use_line_collection=True)\n",
    "plt.title(\"$\\cos\\\\left(\\\\frac{2\\pi}{100} n\\\\right)$\")\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.title(\"$\\cos\\\\left(\\\\frac{10\\pi}{100} n\\\\right)$\")\n",
    "plt.stem(n, fast_cos, use_line_collection=True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "outer-greene",
   "metadata": {},
   "source": [
    "$\\cos\\left(\\frac{10\\pi}{100} t\\right)$ is clearly changing a lot faster. If we allow ourselves to consider complex signals, then we can generalized sinusoids using the complex exponential $e^{j\\omega}$. Just like real sinusoids, the $\\omega$ in the signal $x[n] = e^{j\\omega n}$ determines how fast the signal changes (i.e rotates around the unit circle). If we can somehow \"project\" our time-domain signal $x[n]$ onto a \"basis\" of complex exponential signals, then, then the coefficients $X[k]$ should tell us how much the signal changes.\n",
    "\n",
    "The Discrete Fourier Transform is the change of basis which we use for a finite, length-$N$ signal to understand how fast it is changing. The basis used in the DFT are the $N$th roots of unity (i.e the complex solutions to $\\omega=1$). More specifically, the $k$th basis vector is given by $\\phi_k[n] = e^{j\\frac{2\\pi}{N}kn}$. Using the complex inner product $\\langle \\vec{x}, \\vec{y} \\rangle = \\vec{y}^*\\vec{x}$, the DFT coefficients are given by\n",
    "\n",
    "$$X[k] = \\langle x, \\phi_k \\rangle = \\sum_{n=0}^{N-1}x[n]e^{-j\\frac{2\\pi}{N}kn}$$.\n",
    "\n",
    "From the DFT coefficients, we can recover the time-domain coefficients using the inverse DFT.\n",
    "\n",
    "$$x[n] = \\frac{1}{N} \\sum_{k=0}^{N-1}X[k]e^{j\\frac{2\\pi}{N}kn}$$.\n",
    "\n",
    "There are many ways to compute the DFT. The fastest method is the Fast Fourier Transform (FFT), which is an algorithm which computes the DFT. It is built into `numpy` as part of the `fft` submodule.\n",
    "\n",
    "If we look at the DFT coefficients of the two cosines we saw earlier, we can see that it is indeed doing exactly what we wanted it to: characterizing the frequency of the signal."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "boolean-encounter",
   "metadata": {},
   "outputs": [],
   "source": [
    "slow_cos_fft = np.fft.fft(slow_cos)\n",
    "fast_cos_fft = np.fft.fft(fast_cos)\n",
    "\n",
    "plt.figure(figsize=(15, 7))\n",
    "plt.subplot(2, 2, 1)\n",
    "plt.stem(n, np.abs(slow_cos_fft), use_line_collection=True)\n",
    "plt.title(\"$|DFT\\{\\cos\\\\left(\\\\frac{2\\pi}{100} n\\\\right)\\}|$\")\n",
    "plt.subplot(2, 2, 2)\n",
    "plt.title(\"$|DFT\\{\\cos\\\\left(\\\\frac{10\\pi}{100} n\\\\right)\\}|$\")\n",
    "plt.stem(n, np.abs(fast_cos_fft), use_line_collection=True)\n",
    "plt.subplot(2, 2, 3)\n",
    "plt.stem(n, np.angle(slow_cos_fft), use_line_collection=True)\n",
    "plt.title(\"$\\\\arg \\\\left(DFT\\{\\cos\\\\left(\\\\frac{2\\pi}{100} n\\\\right)\\}\\\\right)$\")\n",
    "plt.subplot(2, 2, 4)\n",
    "plt.title(\"$\\\\arg \\\\left(DFT\\{\\cos\\\\left(\\\\frac{10\\pi}{100} n\\\\right)\\}\\\\right)$\")\n",
    "plt.stem(n, np.angle(fast_cos_fft), use_line_collection=True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "pediatric-federal",
   "metadata": {},
   "source": [
    "Since $\\cos\\left(\\frac{2\\pi}{100}n\\right) = \\frac{1}{2}\\left(e^{j\\frac{2\\pi}{100}n} + e^{-j\\frac{2\\pi}{100}n}\\right)$, we should expect peaks at $k = 1$ and $k =-1$ (note that because the roots of unity are periodic, $k=-1$ is the same basis vector as $k=99$). Likewise, since $\\cos\\left(\\frac{10\\pi}{100}n\\right) = \\frac{1}{2}\\left(e^{j\\frac{10\\pi}{100}n} + e^{-j\\frac{10\\pi}{100}n}\\right)$, we should expect peaks at $k=5$ and $k=-5$.\n",
    "\n",
    "There are a few things to note:\n",
    "1. The DFT coefficients are complex numbers, so we need both magnitude (top plots) and phase (bottom plots) to characterize the signal information\n",
    "2. For both $\\cos\\left(\\frac{2\\pi}{100}n\\right)$ and $\\cos\\left(\\frac{10\\pi}{100}n\\right)$, we should only expect 2 non-zero coefficients. However, we have apparently many non-zero coefficients. These are due to numerical instability in the DFT algorithm (if you print them out, these coefficients are on the order of $10^{-3}$ in magnitude and so are insignificant).\n",
    "3. The DFT basis is **not** orthonormal. This is why we must scale by $\\frac{1}{N}$ when applying the inverse DFT (`np.fft.ifft` in numpy). This is also why the peak magnitudes of the example signals above are 50 and not $\\frac{1}{2}$.\n",
    "4. DFT basis vectors are complex conjugates of each other (i.e $\\phi_k[n] = \\phi_{N-k}[n]^*$). This means for real signals, $X[k] = X^*[N-k]$.\n",
    "\n",
    "### Exercise"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "portable-precipitation",
   "metadata": {},
   "source": [
    "To get a better feel for the DFT, compute and plot the magnitude of the DFT coefficients of our clip from Tom's Diner in decibels ($dB = 20\\log_{10}(X[k])$). Since our song is a real signal, do not plot the complex conjugate coefficients since they are redundant information."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "horizontal-publication",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(15, 7))\n",
    "\n",
    "# ** YOUR CODE HERE ** #\n",
    "song_dft = 20 * np.log10(np.abs(np.fft.fft(audio)))\n",
    "plt.plot(song_dft[:audio.size // 2]) # Coefficents N/2 to N are complex coefficients\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "nearby-pastor",
   "metadata": {},
   "source": [
    "**Comprehension Question**: Do you notice anything interesting about the chart above?\n",
    "\n",
    "**Answer**: Around index 150,000, there is a sharp decline in the magnitude of the DFT coefficients. It turns out that this DFT coefficient represents approximately 12.5 kHz (we'll see how to compute this later), which is close to the human hearing limit of about 20kHz."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "impossible-garbage",
   "metadata": {},
   "source": [
    "**Comprehension Question**: What does the first coefficient $X[0]$ of the DFT represent in simple terms?\n",
    "\n",
    "**Answer**: It is the sum of the signal (we can see this from the formula by letting $k=0$)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "pharmaceutical-salem",
   "metadata": {},
   "source": [
    "## II.a PSD\n",
    "\n",
    "In signal processing, due to noise, numerical stability, and other issues, we often care about the dominant frequencies in the signal (e.g when we are looking for formants in a vowel). This means we want to look at the magnitude of the DFT coefficients. However, sometimes peaks in the DFT are difficult to distinguish when looking at a magnitude plot. To better distinguish peaks, we can instead look at $|X[k]|^2$, the so-called **Power Spectral Density (PSD)**.\n",
    "\n",
    "The Power Spectral Density is the essentially the magnitude of the DFT of the auto-correlation of the signal $x$. This is because when $x[n]$ has DFT coefficients $X[k]$, then $x[-n]$ has DFT coefficients $X^*[k]$ and since auto-correlation is the convolution of $x[n] * x[-n]$, and convolution in the time-domain is multiplication in the frequency domain, $PSD = X[k] X^*[k] = |X[k]|^2$."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "empirical-petersburg",
   "metadata": {},
   "source": [
    "### Exercise\n",
    "\n",
    "Use the PSD to guess what vowels these are."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "individual-defensive",
   "metadata": {},
   "outputs": [],
   "source": [
    "vowel_1 = audio[int(7.25 * fs):int(fs * 7.45)] # ai\n",
    "vowel_2 = audio[int(11.45 * fs):int(11.70 * fs)] # e"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "massive-faith",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(15, 7))\n",
    "\n",
    "plt.subplot(2, 1, 1)\n",
    "\n",
    "# ** YOUR CODE HERE ** #\n",
    "vowel_1_dft = np.abs(np.fft.fft(vowel_1)) ** 2\n",
    "plt.plot(vowel_1_dft[:200]) # Coefficents N/2 to N are complex coefficients\n",
    "\n",
    "plt.subplot(2, 1, 2)\n",
    "# ** YOUR CODE HERE ** #\n",
    "vowel_2_dft = np.abs(np.fft.fft(vowel_2)) ** 2\n",
    "plt.plot(vowel_2_dft[:200]) # Coefficents N/2 to N are complex coefficients\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "transparent-filter",
   "metadata": {},
   "source": [
    "# III. Frequency Domain Filtering - Jordan"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "interesting-andrew",
   "metadata": {},
   "source": [
    "# IV. Sampling Theory - Anmol"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "pharmaceutical-mambo",
   "metadata": {},
   "source": [
    "## IV.a Aliasing"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "noticed-necessity",
   "metadata": {},
   "source": [
    "## IV.b Quantization"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "tracked-parks",
   "metadata": {},
   "source": [
    "# V. Spectral Analysis - Hoang"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "determined-voice",
   "metadata": {},
   "source": [
    "## V.a Windowing"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "87212bd6",
   "metadata": {},
   "source": [
    "**Why?**\n",
    "* We can only capture a finite length of a signal\n",
    "* Impossible to capture an infinitely long signal (x[n] from $n = -\\infty$ to $n = \\infty$\n",
    "\n",
    "**How?**\n",
    "* Time domain: Multiple the signal x[n] with a window: $x[n] \\cdot w[n]$\n",
    "* Frequency domain: Convolution between the spectrum and the DTFT of the window, thus blurring the spectrum\n",
    "\n",
    "**Popular Windows**\n",
    "* Rectangular (never use this due to excessive sidelobe leakage)\n",
    "* Hann\n",
    "* Hamming\n",
    "* Tukey\n",
    "* Blackman\n",
    "* ...\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "powered-exhaust",
   "metadata": {},
   "source": [
    "## V.b STFT/Spectrogram\n",
    "\n",
    "**Overview**\n",
    "\n",
    "<img src=\"./images/STFT_steps.png\" alt=\"Step-by-step to perform STFT\" width=\"700\"/>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22c961a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Audio signal attributes\n",
    "N = audio.size\n",
    "Tmax = N/fs\n",
    "print(f\"Sampling rate: {fs} Hz\")\n",
    "print(f\"Number of samples: {N} samples\")\n",
    "print(f\"Duration of recording: {Tmax} seconds\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4659e643",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Design Parameters\n",
    "Tw_s = 1.0 # window duration (seconds)\n",
    "s_s = 0.01 # step size (seconds)\n",
    "M = 4096 # number of frequencies (number of zeropadding)\n",
    "L = 296 # length of autocorrelation window (samples)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b3809c2",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "n = np.arange(N)\n",
    "t = np.linspace(0, Tmax, N)\n",
    "Tw = int(np.round(Tw_s * fs)) # window duration (samples)\n",
    "s = int(np.round(s_s * fs)) # step size (samples)\n",
    "nS = int(np.ceil((N-Tw)/s)) # number of steps\n",
    "\n",
    "print(f\"Data window duration: {Tw} (samples)\")\n",
    "print(f\"Step size: {s} (samples)\")\n",
    "print(f\"Number of steps: {nS} (steps)\")\n",
    "\n",
    "# Divide the signal into segments of length Tw (window duration)\n",
    "audio_segs = []\n",
    "for idx in [int(i) for i in np.arange(0, N-Tw, s)]:\n",
    "    audio_segs.append(audio[idx:idx+Tw])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee7dbac2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def autocorrelation(x, fs, ml):\n",
    "    '''\n",
    "        x (numpy.ndarray): time-domain signal\n",
    "        fs (float): sampling rate (Hz)\n",
    "        ml (int): maximum lag (samples)\n",
    "    '''\n",
    "    nx = len(x) # number of samples in signal\n",
    "    ml = min(ml, nx) # maximum lag\n",
    "    mx = np.mean(x) # mean of signal\n",
    "    vx = np.var(x) # variance of signal\n",
    "    x = x - mx; # remove the mean (DC component) from the signal\n",
    "\n",
    "    nz = int(2**np.ceil(np.log2(np.abs(2*nx-1)))) # number of zeropadding\n",
    "    X  = np.fft.fft(x, nz)\n",
    "    xc = np.fft.ifft(np.abs(X)**2)\n",
    "    ac = np.real(xc[1:ml])\n",
    "    ac = ac/nx # biased form of autocorrelation estimate\n",
    "    ac = ac/ac[0]\n",
    "\n",
    "    return ac"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0a548a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute the spectrogram\n",
    "k = np.arange(0, M)\n",
    "we = k * (2*np.pi/M) # angular frequency of estimate (rad/s)\n",
    "fe = k * fs/M # frequency of estimate (Hz)\n",
    "wd = np.blackman(Tw) # data window\n",
    "wa = np.blackman(L) # autocorrelation window\n",
    "PSD_segs = []\n",
    "for idx in [int(i) for i in np.arange(0, nS)]:\n",
    "    # Window the signal then compute the autocorrelation\n",
    "    r_x_tmp = autocorrelation(audio_segs[idx] * wd, fs, Tw+1)\n",
    "    r_x = np.concatenate((np.flip(r_x_tmp[1:-1]), r_x_tmp))\n",
    "    \n",
    "    # Window the autocorrelation\n",
    "    if L >= len(r_x):\n",
    "        r_v = r_x * wa[int(abs(L-len(r_x))/2) : int(len(r_x)-1-abs(L-len(r_x))/2)];\n",
    "    else:\n",
    "        # TODO: debug here\n",
    "        r_v = wa * r_x[int(abs(L-len(r_x))/2) : int(len(r_x)-1-abs(L-len(r_x))/2)];\n",
    "\n",
    "    # Compute the PSD\n",
    "    PSD_segs.append(np.exp(-1j * we * 1) * np.fft.fft(r_v, M))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "laughing-intermediate",
   "metadata": {},
   "source": [
    "## V.c Spectral Estimation Methods\n",
    " \n",
    "**Periodogram**\n",
    "* Has excessive variance\n",
    "\n",
    "**Blackman-Tukey**\n",
    "* Reduce variance by smoothing the periodogram\n",
    "\n",
    "**Welch-Bartlett**\n",
    "* Reduce variance by averaging the periodogram"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "altered-samba",
   "metadata": {},
   "source": [
    "## V.c Tradeoffs when performing spectral analysis\n",
    "\n",
    "**Overview**\n",
    "\n",
    "|      Spectrogram Design Parameters     |                              Tradeoffs                             |\n",
    "|:--------------------------------------:|:------------------------------------------------------------------:|\n",
    "|               Window types             |      Frequency resolution (mainlobe width) vs. Sidelobe leakage    |\n",
    "|           Data window duration         |     Frequency resolution vs. Time resolution; Bias vs. Variance    |\n",
    "|     Autocorrelation window duration    |                          Bias vs. Variance                         |\n",
    "|            Step size/Overlap           |                   Computation power vs. Resolution                 |\n",
    "\n",
    "**Data window duration tradeoff**\n",
    "\n",
    "|     Data Window Duration    |     Frequency Resolution    |     Time Resolution    |     PSD Bias    |     PSD Variance    |\n",
    "|:---------------------------:|:---------------------------:|:----------------------:|:---------------:|:-------------------:|\n",
    "|             Long            |             High            |           Low          |        Low      |         High        |\n",
    "|             Short           |              Low            |           High         |       High      |          Low        |\n",
    "\n",
    "**Autocorrelation window duration tradeoff**\n",
    "\n",
    "<img src=\"./images/autocorrelation_window_duration_tradeoff.png\" alt=\"Autocorrelation window duration tradeoff\" width=\"250\"/>\n",
    "\n",
    "**Step size/Overlap tradeoff**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "coordinate-threshold",
   "metadata": {},
   "source": [
    "# Resources\n",
    "\n",
    "1. [Anmol's Course Notes from EE120 (Signals and Systems)](https://aparande.gitbook.io/berkeley-notes/ee120-0)\n",
    "2. [Anmol's Course Notes from EE123 (Digital Signal Processing)](https://aparande.gitbook.io/berkeley-notes/ee123-0)\n",
    "3. [Discrete Time Signal Formula Sheet](https://anmolparande.com/resources/berkeley/discrete-formula-sheet.pdf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "moral-liability",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
